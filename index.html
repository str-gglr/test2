<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Sigil Logic Scanner</title>
    <script src="opencv.js" defer></script>
    <style>
        body { margin: 0; background: #000; font-family: monospace; color: #fff; overflow: hidden; display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100vh; }
        #camContainer { position: relative; width: 100vw; height: 100vw; max-width: 500px; }
        video { position: absolute; width: 100%; height: 100%; object-fit: cover; filter: grayscale(1); opacity: 0.5; }
        canvas#overlay { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 5; pointer-events: none; }
        #result { font-size: 3rem; font-weight: bold; color: #0f0; margin-top: 20px; min-height: 1.2em; }
    </style>
</head>
<body>
    <div id="camContainer">
        <video id="video" autoplay playsinline muted></video>
        <canvas id="overlay"></canvas>
    </div>
    <div id="result">---</div>

<script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const oCtx = overlay.getContext('2d');
    const resultDisplay = document.getElementById('result');

    let cvReady = false, lastScan = 0, lockUntil = 0;
    const GRID = 400;
    const hCanvas = document.createElement('canvas');
    hCanvas.width = hCanvas.height = GRID;
    const hCtx = hCanvas.getContext('2d');

    window.onload = () => {
        let check = setInterval(() => {
            if (typeof cv !== 'undefined' && cv.Mat) { cvReady = true; clearInterval(check); start(); }
        }, 100);
    };

    async function start() {
        const s = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
        video.srcObject = s;
        video.onloadedmetadata = () => { 
            overlay.width = overlay.height = camContainer.clientWidth; 
            requestAnimationFrame(loop); 
        };
    }

    function loop(t) {
        if (cvReady && video.readyState === video.HAVE_ENOUGH_DATA) {
            if (t > lockUntil && t - lastScan > 333) { // 3 FPS
                oCtx.clearRect(0, 0, overlay.width, overlay.height);
                process(t); lastScan = t;
            }
        }
        requestAnimationFrame(loop);
    }

    function process(now) {
        const d = Math.min(video.videoWidth, video.videoHeight);
        hCtx.drawImage(video, (video.videoWidth-d)/2, (video.videoHeight-d)/2, d, d, 0, 0, GRID, GRID);
        let src = cv.imread(hCanvas), gray = new cv.Mat(), bin = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
        cv.adaptiveThreshold(gray, bin, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2);

        let contours = new cv.MatVector(), hierarchy = new cv.Mat();
        cv.findContours(bin, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

        let maxI = -1, maxA = 0;
        for (let i = 0; i < contours.size(); ++i) {
            let a = cv.contourArea(contours.get(i));
            if (a > maxA) { maxA = a; maxI = i; }
        }

        if (maxI !== -1 && maxA > 4000) {
            let approx = new cv.Mat(), hull = new cv.Mat();
            cv.convexHull(contours.get(maxI), hull);
            cv.approxPolyDP(hull, approx, 0.08 * cv.arcLength(hull, true), true);

            if (approx.rows === 3) {
                // Find raw corner points
                let pts = [];
                for(let i=0; i<3; i++) pts.push({x: approx.data32S[i*2], y: approx.data32S[i*2+1]});
                
                // Identify Corners based on raw coordinate position
                // For logic, we need to know which of the 3 possible orientations we are in.
                const corners = sortRaw(pts); 
                const data = sampleMesh(gray, corners);
                
                drawWireframe(corners, data.bits); // Visual stays locked to angle

                if (data.id !== null) {
                    resultDisplay.textContent = data.id.toString().padStart(3, '0');
                    lockUntil = now + 3000; // 3s Refresh
                    navigator.vibrate(50);
                }
            }
            approx.delete(); hull.delete();
        }
        src.delete(); gray.delete(); bin.delete(); contours.delete(); hierarchy.delete();
    }

    function sortRaw(pts) {
        pts.sort((a,b) => a.y - b.y);
        const top = pts[0];
        const base = [pts[1], pts[2]].sort((a,b) => a.x - b.x);
        return { p0: top, p1: base[0], p2: base[1] }; // Raw p0=top, p1=left, p2=right
    }

    function sampleMesh(mat, c) {
        let rawBits = [];
        // Extract 16 raw brightness values
        for (let r = 0; r < 4; r++) {
            for (let i = 0; i < (r * 2 + 1); i++) {
                const tY = (r + 0.5) / 4;
                const tX = (i + 0.5) / (r * 2 + 1);
                const y = c.p0.y + (c.p1.y - c.p0.y) * tY;
                const xL = c.p0.x + (c.p1.x - c.p0.x) * tY;
                const xR = c.p0.x + (c.p2.x - c.p0.x) * tY;
                const x = xL + (xR - xL) * tX;
                rawBits.push(mat.ucharPtr(Math.floor(y), Math.floor(x))[0]);
            }
        }

        // Adaptive Thresholding based on the 16 samples
        const sorted = [...rawBits].sort((a,b) => a-b);
        const thresh = (sorted[4] + sorted[11]) / 2; // Midpoint between light and dark clusters
        const bits = rawBits.map(v => v < thresh ? 1 : 0);

        // Logic Re-orientation
        // Check 3 anchor possibilities: Upright, Rotated Left, Rotated Right
        // Anchor positions in 1D array: 0 (Top), 9 (Mid-Left), 15 (Bottom-Right) etc.
        // For simplicity, we assume Anchor 1 is Apex, Anchor 2 is Base-Left.
        
        let id = null;
        const decode = (b) => {
            const D = [b[1], b[3], b[4], b[5], b[7], b[8], b[11], b[12], b[13]];
            const R = [b[2], b[6], b[10], b[14]];
            const C = [D[0]^D[1]^D[3]^D[4]^D[6]^D[8], D[2]^D[3]^D[4]^D[5]^D[7]^D[8], D[0]^D[2]^D[3]^D[6]^D[7], D[1]^D[4]^D[5]^D[7]^D[8]];
            return R.every((v,i) => v === C[i]) ? parseInt(D.join(''), 2) : null;
        };

        // Try standard orientation first
        if (bits[0] === 1 && bits[9] === 1) id = decode(bits);
        
        return { id, bits };
    }

    function drawWireframe(c, bits) {
        const s = overlay.width / GRID;
        oCtx.strokeStyle = "#0f0"; oCtx.lineWidth = 2;
        
        let idx = 0;
        for (let r = 0; r < 4; r++) {
            const tT = r/4, tB = (r+1)/4;
            const yT = (c.p0.y + (c.p1.y-c.p0.y)*tT)*s, yB = (c.p0.y + (c.p1.y-c.p0.y)*tB)*s;
            const xLT = (c.p0.x + (c.p1.x-c.p0.x)*tT)*s, xRT = (c.p0.x + (c.p2.x-c.p0.x)*tT)*s;
            const xLB = (c.p0.x + (c.p1.x-c.p0.x)*tB)*s, xRB = (c.p0.x + (c.p2.x-c.p0.x)*tB)*s;

            for (let i = 0; i < (r*2+1); i++) {
                oCtx.beginPath();
                if (i%2===0) {
                    const n = i/2;
                    oCtx.moveTo(xLT + (xRT-xLT)*(n/r||0), yT);
                    oCtx.lineTo(xLB + (xRB-xLB)*(n/(r+1)), yB);
                    oCtx.lineTo(xLB + (xRB-xLB)*((n+1)/(r+1)), yB);
                } else {
                    const n = (i-1)/2;
                    oCtx.moveTo(xLT + (xRT-xLT)*(n/r), yT);
                    oCtx.lineTo(xLT + (xRT-xLT)*((n+1)/r), yT);
                    oCtx.lineTo(xLB + (xRB-xLB)*((n+1)/(r+1)), yB);
                }
                oCtx.closePath();
                if (bits) {
                    oCtx.fillStyle = bits[idx] ? "rgba(0,255,0,0.3)" : "rgba(255,255,255,0.05)";
                    oCtx.fill();
                }
                oCtx.stroke();
                idx++;
            }
        }
    }
</script>
</body>
</html>